<h2 align="center">web-scraping-githubapi-contributor</h2>

<br>
<h3> ğŸ§ Introduction</h3>
    This project is aimed at extracting the data of hadoop contributors from github api and storing it into mysql database.  

### ğŸ“Š Variables extracted
- Name
- Id
- Location
- Hiring status
- Bio
- Following on github
- Contact information
- Profile URL

### ğŸ’µ Business Outcome:
Data scraped from the internet can be a valuable resource for statistical analysis and research purposes. By storing the data of all contributors on github, a company can easily access the details of potential employees. This information can be used by recruitment team to filter candidates who are hireable and has been contributing to the hadoop space. 
Instead of going through the profile of each and every individual, the sql database can be queried to access the needed information. 

### âš’ï¸ Tools and Technologies Used
- MySQL
- Beautiful soup


<h3>ğŸ”— Contact Me</h3>
 <a href='https://www.linkedin.com/in/aishwarya-ucd/'><img align='center' alt="linkedin" src="https://raw.githubusercontent.com/shahbajjamil/Social-Meadia-Icons/master/Icons-logos/linkedin-circle.png" height='26px'/></a>
